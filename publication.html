<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Guojun Xiong (熊国钧)
</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-129163640-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Guojun Xiong</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="index.html" class="current">Publication</a></div>
<div class="menu-item"><a href="teaching.html">Activities</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=FIBwLnoAAAAJ&hl=zh-CN">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications 
</h1>
<ul>
<li><p><a href="https://arxiv.org/pdf/2405.00950">Provably Efficient Reinforcement Learning for Adversarial Restless Multi-Armed Bandits with Unknown Transitions and Bandit Feedback</a><br />
<b>Guojun Xiong</b>, Jian Li. ICML 2024. <a href="https://arxiv.org/pdf/2405.00950">[arXiv]</a>
</p>
</li>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/29543">DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations</a><br />
<b>Guojun Xiong</b>, Gang Yan, Shiqiang Wang, Jian Li. AAAI 2024. <a href="https://arxiv.org/pdf/2312.10815">[arXiv]</a>
</p>
</li>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/29489">Online Restless Multi-Armed Bandits with Long-Term Fairness Constraints</a><br />
Shufan Wang, <b>Guojun Xiong</b>, Jian Li. AAAI 2024.  <a href="https://arxiv.org/pdf/2312.10303">[arXiv]</a>
</p>
</li>
<li><p><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/5c7c66dfc9f93f0c738947f3b1c13832-Paper-Conference.pdf">Finite-Time Analysis of Whittle Index based Q-Learning for Restless Multi-Armed Bandits with Neural Network Function Approximation</a><br />
<b>Guojun Xiong</b>, Jian Li. NeurIPS 2023. <a href="https://arxiv.org/abs/2310.02147">[arXiv]</a>
</p>
</li>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/10021290">Reinforcement Learning for Dynamic Dimensioning of Cloud Caches: A Restless Bandit Approach</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Gang Yan, Jian Li. (IEEE/ACM Transactions on Networking 2023). <a href="https://ieeexplore.ieee.org/abstract/document/10021290">[arXiv]</a>
</p>
</li>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/26251">Decentralized Stochastic Multi-Player Multi-Armed Walking Bandits</a><br />
<b>Guojun Xiong</b>, Jian Li. AAAI 2023. <a href="https://arxiv.org/abs/2212.06279">[arXiv]</a>
</p>
</li>
<li><p><a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/71f003060ce1e8b6b4856023b67cda5d-Paper-Conference.pdf">Learning Infinite-Horizon Average-Reward Restless Multi-Action Bandits via Index Awareness</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Jian Li.  Proceedings of the Thirty-sixth Conference on Neural Information Processing Systems, New Orleans, LA, November 2022.. <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/71f003060ce1e8b6b4856023b67cda5d-Paper-Conference.pdf">[paper]</a>
</p>
</li>
<li><p><a href="https://dl.acm.org/doi/abs/10.1145/3492866.3549726"> Index-Aware Reinforcement Learning for Adaptive Video Streaming at the Wireless Edge</a><br />
<b>Guojun Xiong</b>, Xudong Qin, Bin Li, Rahul Singh, Jian Li. ACM Mobihoc 2022. <a href="https://dl.acm.org/doi/abs/10.1145/3492866.3549726">[arXiv]</a>
</p>
</li>
<li><p><a href="https://dl.acm.org/doi/abs/10.1109/INFOCOM48880.2022.9796809">Reinforcement Learning for Dynamic Dimensioning of Cloud Caches: A Restless Bandit Approach</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Gang Yan, Jian Li. Proceedings of IEEE International Conference on Computer Communications (IEEE INFOCOM), 2022. <a href="https://dl.acm.org/doi/abs/10.1109/INFOCOM48880.2022.9796809">[arXiv]</a> 
</p>
</li>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/20852">Reinforcement Learning Augmented Asymptotically Optimal Index Policies for Finite-Horizon Restless Bandits </a><br />
<b>Guojun Xiong</b>, Jian Li, Rahul Singh. AAAI 2022. <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20852">[arXiv]</a> 
</p>
</li>
<li><p><a href="https://proceedings.mlr.press/v162/wang22ai.html">When Are Linear Stochastic Bandits Attackable?</a><br />
<b>Huazheng Wang</b>, Haifeng Xu, Hongning Wang. International Conference on Machine Learning (ICML 2022). <a href="https://arxiv.org/abs/2110.09008">[arXiv]</a>
</p>
</li>

</ul>
  
<h3>Preprints
</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.19218">Adversarial Attacks on Online Learning to Rank with Stochastic Click Models</a><br />
Zichen Wang, Rishab Balasubramanian, Hui Yuan, Chenyu Song, Mengdi Wang, <b>Huazheng Wang</b> <a href="https://arxiv.org/abs/2305.19218">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2310.05308">Adversarial Attacks on Combinatorial Multi-Armed Bandits</a><br />
Rishab Balasubramanian, Jiawei Li, Prasad Tadepalli, <b>Huazheng Wang</b>, Qingyun Wu, Haoyu Zhao  (Alphabetic order). <a href="https://arxiv.org/abs/2310.05308">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2307.12975">Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems</a><br />
Xiang Ji, <b>Huazheng Wang</b>, Minshuo Chen, Tuo Zhao, Mengdi Wang. <a href="https://arxiv.org/abs/2307.12975">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.14846">Provably Efficient Reinforcement Learning for Online Adaptive Influence Maximization</a><br />
Kaixuan Huang, Yu Wu, Xuezhou Zhang, Shenyinying Tu, Qingyun Wu, Mengdi Wang, <b>Huazheng Wang</b>. <a href="https://arxiv.org/abs/2206.14846">[arXiv]</a>
</p>
</li>
</ul>
<h3>Tutorials
</h3>
<ul>
<li><p><a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/">Interactive Information Retrieval with Bandit Feedback</a><br /> <b>Huazheng Wang</b>, Yiling Jia, Hongning Wang,
SIGIR 2021. <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/">[Website]</a>  <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/files/Bandit4IR_full.pdf">[Slides]</a>
</p>
</li>
<li><p><a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/">Learning by Exploration: New Challenges in Real-World Environments</a><br /> Qingyun Wu, <b>Huazheng Wang</b>, Hongning Wang,
KDD 2020. <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/">[Website]</a>  <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/files/Learning%20by%20Exploration.pptx">[Slides]</a>
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2024-04-02 15:26:13 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
