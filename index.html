<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Guojun (国钧) Xiong
</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-129163640-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Guojun Xiong</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="index.html" class="current">Publication</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="https://github.com/huazhengwang/">GitHub</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=w3PrbKwAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Guojun (国钧) Xiong
</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photos/bio1.jpg" alt="alt qtext" width="160px" height="190px" />&nbsp;</td>
<td align="left"><p>PhD Candidate,<br />
Department of Applied Mathematics and Statistics, <br />
Department of Computer Science, <br />
College of Engineering and Applied Sciences
Stony Brook University<br />
Email: guojun.xiong [at] stonybrook.edu
</p>
</td></tr></table>
<h2>About me
</h2>
<p>I am an incoming postdoctoral fellow in the Department of Computer Science at Harvard University, hosted by <a href="https://teamcore.seas.harvard.edu/tambe">Prof. Milind Tambe</a>, and supported by the <a href="https://crcs.seas.harvard.edu/"> Harvard Center for Research on Computation and Society (CRCS)</a>.  I am currently a fourth-year PhD student in the Department of Applied Mathematics and the Department of Computer Science at Stony Brook University, supervised by <a href="https://sites.google.com/stonybrook.edu/jianli/home?authuser=0">Dr. Jian Li</a>. Prior to my PhD, I received my B.E. from Sun Yat-sen University, Guangzhou, China, and my M.S. from University of Kansas, Lawrence, both in Electrical Engineering. 
My research interests include reinforcement learning, information retrieval, and machine learning in general. Currently I focus on multi-armed bandits and reinforcement learning with application to online recommendation and other information retrieval problems.
</p>
<p><font color=red> Updates: I am looking for self-motivated PhD students with solid math and coding backgrounds starting Fall 2024. More information can be found here for <a href="prospective_students.html">prospective students</a>.</font></p>
<h3>News and Updates
</h3>
<ul>
<li><p>[01/2024] One <a href="https://arxiv.org/abs/2308.02585">paper</a> on policy alignment is accepted by ICLR 2024.
</p>
</li>
<li><p>[12/2023] Two papers accepted by AAAI 2024: one on <a href="https://arxiv.org/abs/2401.06173">tree search bandits for protein optimization</a> and one on stealthy attack against MAB.
</p>
</li>
<li><p>[09/2023] One paper on offline RL for learning to rank is accepted by NeurIPS 2023.
</p>
</li>
<li><p>[04/2023] One paper on representation learning in POMDP is accepted by ICML 2023. See you in Hawaii.
</p>
</li>
<li><p>[01/2023] Our <a href="https://openreview.net/forum?id=-G1kjTFsSsdistributed">asynchronous kernel bandits</a> paper is accepted by ICLR 2023.
</p>
</li>
<li><p>[09/2022] Two papers accepted by NeurIPS 2022: one on <a href="https://arxiv.org/abs/2206.04835">distributed kernel bandits</a> and the other on <a href="https://arxiv.org/abs/2206.02092">Thompson Sampling for Directed Evolution</a>. 
</p>
</li>
<li><p>[09/2022] Joined EECS at Oregon State University as an Assistant Professor.
</p>
</li>
</ul>
<h3>Honors and Awards
</h3>
<ul>
<li><p>[08/2019], <a href="http://sigir.org/awards/best-paper-awards/">SIGIR 2019 Best Paper Award</a>.
</p>
</li>
<li><p>[2018 - 2021], Bloomberg Data Science Ph.D. Fellowship.
</p>
</li>
<li><p>[08/2021], ICML 2021 Best Reviewers (Top 10%).

</p>
</li>
</ul>
<h3>Publications 
</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2308.02585">PARL: A Unified Framework for Policy Alignment in Reinforcement Learning</a><br />
Souradip Chakraborty, Amrit Singh Bedi, Alec Koppel, Dinesh Manocha, <b>Huazheng Wang</b>, Furong Huang, Mengdi Wang. ICLR 2024. <a href="https://arxiv.org/abs/2308.02585">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2401.06173">Tree Search-Based Evolutionary Bandits for Protein Sequence Optimization</a><br />
Jiahao Qiu, Hui Yuan, Jinghong Zhang, Wentao Chen, <b>Huazheng Wang</b>, Mengdi Wang. AAAI 2024. <a href="https://arxiv.org/abs/2401.06173">[arXiv]</a>
</p>
</li>
<li><p><a href="">Stealthy Adversarial Attacks on Stochastic Multi-Armed Bandits</a><br />
Zhiwei Wang, <b>Huazheng Wang</b>, Hongning Wang. AAAI 2024.
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2306.07528">Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective</a><br />
Zeyu Zhang, Yi Su, Hui Yuan, Yiran Wu, Rishab Balasubramanian, Qingyun Wu, <b>Huazheng Wang</b>, Mengdi Wang. NeurIPS 2023. <a href="https://arxiv.org/abs/2306.07528">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2306.12356">Provably Efficient Representation Learning with Tractable Planning in Low-Rank POMDP</a><br />
Jiacheng Guo, Zihao Li, <b>Huazheng Wang</b>, Mengdi Wang, Zhuoran Yang, Xuezhou Zhang. International Conference on Machine Learning (ICML 2023). <a href="https://arxiv.org/abs/2306.12356">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2104.03860">Incentivizing Exploration in Linear Bandits under Information Gap</a><br />
<b>Huazheng Wang</b>, Haifeng Xu, Chuanhao Li, Zhiyuan Liu, Hongning Wang. Proceedings of the 17th ACM Conference on Recommender Systems (RecSys 2023). <a href="https://arxiv.org/abs/2104.03860">[arXiv]</a>
</p>
</li>
<li><p><a href="https://openreview.net/forum?id=-G1kjTFsSs">Learning Kernelized Contextual Bandits in a Distributed and Asynchronous Environment</a><br />
Chuanhao Li, <b>Huazheng Wang</b>, Mengdi Wang, Hongning Wang.  The Eleventh International Conference on Learning Representations (ICLR 2023). <a href="https://openreview.net/forum?id=-G1kjTFsSs">[paper]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.02092">Bandit Theory and Thompson Sampling-Guided Directed Evolution for Sequence Optimization</a><br />
Hui Yuan, Chengzhuo Ni, <b>Huazheng Wang</b>, Xuezhou Zhang, Le Cong, Csaba Szepesvári, Mengdi Wang. Advances in Neural Information Processing Systems 35 (NeurIPS 2022). <a href="https://arxiv.org/abs/2206.02092">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.04835">Communication Efficient Distributed Learning for Kernelized Contextual Bandits</a><br />
Chuanhao Li, <b>Huazheng Wang</b>, Mengdi Wang, Hongning Wang. Advances in Neural Information Processing Systems 35 (NeurIPS 2022). <a href="https://arxiv.org/abs/2206.04835">[arXiv]</a> 
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2208.14555">Dynamic Global Sensitivity for Differentially Private Contextual Bandits</a><br />
<b>Huazheng Wang</b>, David Zhao, Hongning Wang. Proceedings of the 16th ACM Conference on Recommender Systems (RecSys 2022). <a href="https://arxiv.org/abs/2208.14555">[arXiv]</a> 
</p>
</li>
<li><p><a href="https://proceedings.mlr.press/v162/wang22ai.html">When Are Linear Stochastic Bandits Attackable?</a><br />
<b>Huazheng Wang</b>, Haifeng Xu, Hongning Wang. International Conference on Machine Learning (ICML 2022). <a href="https://arxiv.org/abs/2110.09008">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2103.00368">PairRank: Online Pairwise Learning to Rank by Divide-and-Conquer</a><br />
Yiling Jia, <b>Huazheng Wang</b>, Stephen Guo, Hongning Wang, Proceedings of the Web Conference 2021 (WWW 2021).  <font color=red>Nominated for the Best Paper Award</font> <a href="https://arxiv.org/abs/2103.00368">[arXiv]</a> <a href="https://github.com/yilingjia/PairRank">[code]</a>
</p>
</li>
<li><p><a href="papers/RecSys2020_DPCoLin_Wang.pdf">Global and Local Differential Privacy for Collaborative Bandits</a><br />
<b>Huazheng Wang</b>, Qian Zhao, Qingyun Wu, Shubham Chopra, Abhinav Khaitan, Hongning Wang, Fourteenth ACM Conference on Recommender Systems (RecSys 2020). <a href="papers/RecSys2020_DPCoLin_Wang.pdf">[pdf]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2004.13574">Unbiased Learning to Rank: Online or Offline?</a><br />
Qingyao Ai, Tao Yang, <b>Huazheng Wang</b>, Jiaxin Mao, ACM Transactions on Information Systems (TOIS). <a href="https://arxiv.org/abs/2004.13574">[arXiv]</a> <a href="https://github.com/ULTR-Community/ULTRA">[code]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2007.08561">A Smoothed Analysis of Online Lasso for the Sparse Linear Contextual Bandits Problem</a><br /> 
Zhiyuan Liu, <b>Huazheng Wang</b>, Bo Waggoner, Youjian(Eugene) Liu, Lijun Chen, Workshop on Real World Experiment Design and Active Learning at ICML 2020. <a href="https://arxiv.org/abs/2007.08561">[arXiv]</a>
</p>
</li>
<li><p><a href="papers/AAAI2020_RewardDrift_Liu.pdf">Incentivized Exploration for Multi-Armed Bandits under Reward Drift</a><br />
Zhiyuan Liu*, <b>Huazheng Wang</b>*, Fan Shen, Kai Liu and Lijun Chen, The 34th AAAI Conference on Artifical Intelligence (AAAI 2020). <a href="https://arxiv.org/abs/1911.05142">[arXiv]</a>
</p>
</li>
<li><p><a href="papers/EMNLP2019_AdaMRC_Wang.pdf">Adversarial Domain Adaptation for Machine Reading Comprehension</a><br /> <b>Huazheng Wang</b>, Zhe Gan, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Hongning Wang, (EMNLP 2019). <a href="https://arxiv.org/abs/1908.09209">[arXiv]</a>
</p>
</li>
<li><p><a href="papers/SIGIR2019-DocumentSpace-Wang.pdf">Variance Reduction in Gradient Exploration for Online Learning to Rank</a><br />
<b>Huazheng Wang</b>, Sonwoo Kim, Eric McCord-Snook, Qingyun Wu, Hongning Wang, The 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2019). <font color=red>Best Paper Award</font> <a href="https://arxiv.org/abs/1906.03766">[arXiv]</a> <a href="https://github.com/sak2km/OnlineLearningToRank">[code]</a>
</p>
</li>
<li><p><a href="papers/KDD2019_MatrixFactorizationIM_Wu.pdf">Factorization Bandits for Online Influence Maximization</a><br />
Qingyun Wu, Zhige Li, <b>Huazheng Wang</b>, Wei Chen, Hongning Wang, The 25th ACM SIGKDD Conference On Knowledge Discovery And Data Mining (KDD 2019). <a href="https://arxiv.org/abs/1906.03737">[arXiv]</a> <a href="https://github.com/Matrix-Factorization-Bandit/IMFB-KDD2019">[code]</a>
</p>
</li>
<li><p><a href="papers/WWW2019-DenBandit-Wu.pdf">Dynamic Ensemble of Contextual Bandits to Satisfy Users&rsquo; Changing Interests</a><br />
Qingyun Wu, <b>Huazheng Wang</b>, Yanen Li, Hongning Wang, The Web Conference 2019 (WWW 2019). <a href="papers/WWW2019-DenBandit-Wu.pdf">[pdf]</a>  <a href="https://github.com/qingyun-wu/NonstationaryBanditLib">[code]</a>
</p>
</li>
<li><p><a href="papers/SIGIR18_NSGD_Wang.pdf">Efficient Exploration of Gradient Space for Online Learning to Rank</a><br />
<b>Huazheng Wang</b>, Ramsey Langley, Sonwoo Kim, Eric McCord-Snook, Hongning Wang, The 41th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2018). <a href="https://arxiv.org/pdf/1805.07317.pdf">[arXiv]</a> <a href="https://github.com/sak2km/OnlineLearningToRank">[code]</a>
</p>
</li>
<li><p><a href="papers/AAAI17_FactorUCB_Wang.pdf">Factorization Bandits for Interactive Recommendation</a><br />
<b>Huazheng Wang</b>, Qingyun Wu, Hongning Wang,  The 31st AAAI Conference on Artifical Intelligence (AAAI 2017). <a href="papers/AAAI17_FactorUCB_Wang.pdf">[pdf]</a> <a href="papers/AAAI17_FactorUCB_Wang_Supp.pdf">[Supplementary]</a> <a href="https://github.com/huazhengwang/banditlib">[code]</a>
</p>
</li>
<li><p><a href="papers/CIKM16_hLinUCB_Wang.pdf">Learning Hidden Features for Contextual Bandits</a><br />
<b>Huazheng Wang</b>, Qingyun Wu, Hongning Wang, The 25th ACM International Conference on Information and Knowledge Management (CIKM 2016). <a href="papers/CIKM16_hLinUCB_Wang.pdf">[pdf]</a> <a href="https://github.com/huazhengwang/banditlib">[code]</a>
</p>
</li>
<li><p><a href="papers/SIGIR16_CoLin_Wu.pdf">Contextual Bandits in A Collaborative Environment</a><br />
Qingyun Wu, <b>Huazheng Wang</b>, Quanquan Gu, Hongning Wang, The 39th  International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2016). <a href="papers/SIGIR16_CoLin_Wu.pdf">[pdf]</a> <a href="https://github.com/huazhengwang/banditlib">[code]</a>
</p>
</li>
<li><p><a href="papers/EMNLP16_iq_test_Wang.pdf">Solving Verbal Comprehension Problems in IQ Test by Knowledge-Powered Word Embedding</a><br />
<b>Huazheng Wang</b>, Fei Tian, Bin Gao, Chengjieren Zhu, Jiang Bian, Tie-Yan Liu, Conference on Empirical Methods in Natural Language Processing, 2016 (EMNLP-16). <a href="https://arxiv.org/abs/1505.07909">[arXiv]</a> <a href="https://www.dropbox.com/s/o0very1gwv3mrt5/VerbalQuestions.zip?dl=0">[data]</a>
</p>
</li>
</ul>
<h3>Preprints
</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.19218">Adversarial Attacks on Online Learning to Rank with Stochastic Click Models</a><br />
Zichen Wang, Rishab Balasubramanian, Hui Yuan, Chenyu Song, Mengdi Wang, <b>Huazheng Wang</b> <a href="https://arxiv.org/abs/2305.19218">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2310.05308">Adversarial Attacks on Combinatorial Multi-Armed Bandits</a><br />
Rishab Balasubramanian, Jiawei Li, Prasad Tadepalli, <b>Huazheng Wang</b>, Qingyun Wu, Haoyu Zhao  (Alphabetic order). <a href="https://arxiv.org/abs/2310.05308">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2307.12975">Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems</a><br />
Xiang Ji, <b>Huazheng Wang</b>, Minshuo Chen, Tuo Zhao, Mengdi Wang. <a href="https://arxiv.org/abs/2307.12975">[arXiv]</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.14846">Provably Efficient Reinforcement Learning for Online Adaptive Influence Maximization</a><br />
Kaixuan Huang, Yu Wu, Xuezhou Zhang, Shenyinying Tu, Qingyun Wu, Mengdi Wang, <b>Huazheng Wang</b>. <a href="https://arxiv.org/abs/2206.14846">[arXiv]</a>
</p>
</li>
</ul>
<h3>Tutorials
</h3>
<ul>
<li><p><a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/">Interactive Information Retrieval with Bandit Feedback</a><br /> <b>Huazheng Wang</b>, Yiling Jia, Hongning Wang,
SIGIR 2021. <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/">[Website]</a>  <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/files/Bandit4IR_full.pdf">[Slides]</a>
</p>
</li>
<li><p><a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/">Learning by Exploration: New Challenges in Real-World Environments</a><br /> Qingyun Wu, <b>Huazheng Wang</b>, Hongning Wang,
KDD 2020. <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/">[Website]</a>  <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/files/Learning%20by%20Exploration.pptx">[Slides]</a>
</p>
</li>
</ul>
<h3>Service
</h3>
<ul>
<li><p>Area Chair: ICLR 2023, 2024; NeurIPS 2023; KDD 2024
</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
